{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daaf11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, mean_absolute_percentage_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13595785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    airline   flight source_city departure_time stops   arrival_time  \\\n",
      "0  SpiceJet  SG-8709       Delhi        Evening  zero          Night   \n",
      "1  SpiceJet  SG-8157       Delhi  Early_Morning  zero        Morning   \n",
      "2   AirAsia   I5-764       Delhi  Early_Morning  zero  Early_Morning   \n",
      "3   Vistara   UK-995       Delhi        Morning  zero      Afternoon   \n",
      "4   Vistara   UK-963       Delhi        Morning  zero        Morning   \n",
      "\n",
      "  destination_city    class  duration  days_left  price  airline_label  \\\n",
      "0           Mumbai  Economy      2.17          1   5953              4   \n",
      "1           Mumbai  Economy      2.33          1   5953              4   \n",
      "2           Mumbai  Economy      2.17          1   5956              0   \n",
      "3           Mumbai  Economy      2.25          1   5955              5   \n",
      "4           Mumbai  Economy      2.33          1   5955              5   \n",
      "\n",
      "   source_city_label  destination_city_label  departure_time_label  \\\n",
      "0                  2                       5                     3   \n",
      "1                  2                       5                     0   \n",
      "2                  2                       5                     0   \n",
      "3                  2                       5                     1   \n",
      "4                  2                       5                     1   \n",
      "\n",
      "   arrival_time_label  stops_label  \n",
      "0                   4            0  \n",
      "1                   1            0  \n",
      "2                   0            0  \n",
      "3                   2            0  \n",
      "4                   1            0  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv ('/Users/nina/Downloads/mlproject/data/Clean_Dataset.csv')\n",
    "# drop index column and check the datatype\n",
    "data = data.drop(['Unnamed: 0'], axis=1)\n",
    "# label encode three categorical columns\n",
    "le = LabelEncoder()\n",
    "data[\"airline_label\"] = le.fit_transform(data['airline'])\n",
    "data[\"source_city_label\"] = le.fit_transform(data['source_city'])\n",
    "data[\"destination_city_label\"] = le.fit_transform(data['destination_city'])\n",
    "# category time and stops according to sequence\n",
    "\n",
    "def time_label(value):\n",
    "    if value == \"Early_Morning\":\n",
    "        return 0\n",
    "    elif value == \"Morning\":\n",
    "        return 1\n",
    "    elif value == \"Afternoon\":\n",
    "        return 2\n",
    "    elif value == \"Evening\":\n",
    "        return 3\n",
    "    elif value == \"Night\":\n",
    "        return 4\n",
    "    elif value == \"Late_Night\":\n",
    "        return 5\n",
    "\n",
    "def stops_label(value):\n",
    "    if value == \"zero\":\n",
    "        return 0\n",
    "    elif value == \"one\":\n",
    "        return 1\n",
    "    elif value == \"two_or_more\":\n",
    "        return 2\n",
    "    \n",
    "\n",
    "data['departure_time_label'] = data['departure_time'].map(time_label)\n",
    "data['arrival_time_label'] = data['arrival_time'].map(time_label)\n",
    "data['stops_label'] = data['stops'].map(stops_label)\n",
    "\n",
    "# Split Dataframe using groupby()\n",
    "# grouping by economy and business class\n",
    "data['class_label'] = np.where(data['class'] == \"Economy\", True, False)\n",
    "grouped = data.groupby(data.class_label)\n",
    "economyData = grouped.get_group(True)\n",
    "economyData=economyData.drop(['class_label'],axis=1)\n",
    "print(economyData.head())\n",
    "data=economyData.drop(['airline', 'flight', 'source_city','departure_time','stops','arrival_time', 'destination_city','class'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9f20f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  days_left  airline_label  source_city_label  \\\n",
      "0      2.17          1              4                  2   \n",
      "1      2.33          1              4                  2   \n",
      "2      2.17          1              0                  2   \n",
      "3      2.25          1              5                  2   \n",
      "4      2.33          1              5                  2   \n",
      "\n",
      "   destination_city_label  departure_time_label  arrival_time_label  \\\n",
      "0                       5                     3                   4   \n",
      "1                       5                     0                   1   \n",
      "2                       5                     0                   0   \n",
      "3                       5                     1                   2   \n",
      "4                       5                     1                   1   \n",
      "\n",
      "   stops_label  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "   price\n",
      "0   5953\n",
      "1   5953\n",
      "2   5956\n",
      "3   5955\n",
      "4   5955\n"
     ]
    }
   ],
   "source": [
    "X=data.drop(['price'],axis=1)\n",
    "y=data[['price']]\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state = 42)\n",
    "rav_train_Y = np.ravel(Train_Y)\n",
    "rav_test_Y = np.ravel(Test_Y)\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab15074",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5db88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7920b34",
   "metadata": {},
   "source": [
    "bagging model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab48f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.09000369583456301\n",
      "Best params are : {'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging = BaggingRegressor()\n",
    "bagging_grid = dict()\n",
    "bagging_grid['n_estimators'] = np.arange(5, 25, 5)\n",
    "\n",
    "bagging_search = GridSearchCV(bagging, bagging_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "bagging_results = bagging_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:' , bagging_results.best_score_)\n",
    "print('Best params are : %s'% bagging_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3551a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.0897292210267557\n",
      "Best params are : {'n_estimators': 22}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging = BaggingRegressor()\n",
    "bagging_grid = dict()\n",
    "bagging_grid['n_estimators'] = np.array([18,19,21,22,23])\n",
    "bagging_search = GridSearchCV(bagging, bagging_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "bagging_results = bagging_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:' , bagging_results.best_score_)\n",
    "print('Best params are : %s'% bagging_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8375fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.089633515698997\n",
      "Best params are : {'n_estimators': 23}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging = BaggingRegressor()\n",
    "bagging_grid = dict()\n",
    "bagging_grid['n_estimators'] = np.array([20,21,22,23,24])\n",
    "bagging_search = GridSearchCV(bagging, bagging_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "bagging_results = bagging_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:' , bagging_results.best_score_)\n",
    "print('Best params are : %s'% bagging_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54d86ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.08885907860489971\n",
      "Best params are : {'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging = BaggingRegressor()\n",
    "bagging_grid = dict()\n",
    "bagging_grid['n_estimators'] = np.array([22,23,25,30,35,40])\n",
    "bagging_search = GridSearchCV(bagging, bagging_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "bagging_results = bagging_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:' , bagging_results.best_score_)\n",
    "print('Best params are : %s'% bagging_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cde8e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.08858018920634736\n",
      "Best params are : {'n_estimators': 60}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging = BaggingRegressor()\n",
    "bagging_grid = dict()\n",
    "bagging_grid['n_estimators'] = np.array([40,50,60])\n",
    "bagging_search = GridSearchCV(bagging, bagging_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "bagging_results = bagging_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:' , bagging_results.best_score_)\n",
    "print('Best params are : %s'% bagging_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "914231d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.0882315163891861\n",
      "Best params are : {'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging = BaggingRegressor()\n",
    "bagging_grid = dict()\n",
    "bagging_grid['n_estimators'] = np.array([70,80,90,100])\n",
    "bagging_search = GridSearchCV(bagging, bagging_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "bagging_results = bagging_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:' , bagging_results.best_score_)\n",
    "print('Best params are : %s'% bagging_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfa8bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.08810972922242126\n",
      "Best params are : {'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging = BaggingRegressor()\n",
    "bagging_grid = dict()\n",
    "bagging_grid['n_estimators'] = np.array([110,120,140])\n",
    "bagging_search = GridSearchCV(bagging, bagging_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "bagging_results = bagging_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:' , bagging_results.best_score_)\n",
    "print('Best params are : %s'% bagging_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ace03e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.0880960256885574\n",
      "Best params are : {'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging = BaggingRegressor()\n",
    "bagging_grid = dict()\n",
    "bagging_grid['n_estimators'] = np.array([150,160])\n",
    "bagging_search = GridSearchCV(bagging, bagging_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "bagging_results = bagging_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:' , bagging_results.best_score_)\n",
    "print('Best params are : %s'% bagging_results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2245a2",
   "metadata": {},
   "source": [
    "after comparsion, the best parameter is n_estimators = 150, the Negative MAPE is -0.0880960256885574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c216a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149610ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60c06a42",
   "metadata": {},
   "source": [
    "random forest tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23698583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.1340710444499974\n",
      "Best params are : {'max_depth': 15, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "#Random forest regression\n",
    "RandomForest_model = RandomForestRegressor()\n",
    "RandomForest_cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define RandomForest_grid\n",
    "RandomForest_grid = dict()\n",
    "RandomForest_grid['max_depth'] = np.array([5,10,15])\n",
    "RandomForest_grid['n_estimators'] = np.array([110,120])\n",
    "\n",
    "RandomForest_search = GridSearchCV(RandomForest_model, RandomForest_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "RandomForest_results = RandomForest_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:', RandomForest_results.best_score_)\n",
    "print('Best params are : %s'% RandomForest_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e164922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.28881683688872434\n",
      "Best params are : {'max_depth': 3, 'random_state': 1}\n"
     ]
    }
   ],
   "source": [
    "#Random forest regression\n",
    "RandomForest_model = RandomForestRegressor()\n",
    "RandomForest_cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define RandomForest_grid\n",
    "RandomForest_grid = dict()\n",
    "RandomForest_grid['max_depth'] = np.array([1,2,3])\n",
    "RandomForest_grid['random_state'] = np.array([None, 1, 2])\n",
    "\n",
    "RandomForest_search = GridSearchCV(RandomForest_model, RandomForest_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "RandomForest_results = RandomForest_search.fit(Train_X, rav_train_Y)\n",
    "print('Negative MAPE:', RandomForest_results.best_score_)\n",
    "print('Best params are : %s'% RandomForest_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed47ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "becca383",
   "metadata": {},
   "source": [
    "decision tree tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75c5f2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "540 fits failed out of a total of 2160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_leaf_nodes' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or None. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-0.09308149 -0.093192   -0.09315243         nan         nan         nan\n",
      " -0.39337256 -0.39337256 -0.39337256 -0.37601572 -0.37601572 -0.37601572\n",
      " -0.25514504 -0.25514504 -0.25514504         nan         nan         nan\n",
      " -0.39337256 -0.39337256 -0.39337256 -0.37601572 -0.37601572 -0.37601572\n",
      " -0.19250984 -0.19251836 -0.19253387         nan         nan         nan\n",
      " -0.39337256 -0.39337256 -0.39337256 -0.37601572 -0.37601572 -0.37601572\n",
      " -0.14281264 -0.14287876 -0.14286276         nan         nan         nan\n",
      " -0.39337256 -0.39337256 -0.39337256 -0.37601572 -0.37601572 -0.37601572\n",
      " -0.09493369 -0.09510431 -0.0949761          nan         nan         nan\n",
      " -0.39337256 -0.39337256 -0.39337256 -0.37601572 -0.37601572 -0.37601572\n",
      " -0.09322638 -0.09317851 -0.09315918         nan         nan         nan\n",
      " -0.39337256 -0.39337256 -0.39337256 -0.37601572 -0.37601572 -0.37601572]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.09308148659075996\n",
      "Best params are : {'max_depth': None, 'max_leaf_nodes': None, 'random_state': None}\n"
     ]
    }
   ],
   "source": [
    "DecisionTree_model = DecisionTreeRegressor()\n",
    "DecisionTree_cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define DecisionTree_grid\n",
    "DecisionTree_grid = dict()\n",
    "\n",
    "DecisionTree_grid['max_depth'] = [None, 5, 10, 15, 25, 30]\n",
    "DecisionTree_grid['max_leaf_nodes'] = [None, 1,2,3]\n",
    "DecisionTree_grid['random_state'] = [None, 1, 2]\n",
    "DecisionTree_search = GridSearchCV(DecisionTree_model, DecisionTree_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "DecisionTree_results = DecisionTree_search.fit(Train_X, Train_Y)\n",
    "print('Negative MAPE:' , DecisionTree_results.best_score_)\n",
    "print('Best params are : %s'% DecisionTree_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e8f5040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.09286160783203476\n",
      "Best params are : {'max_depth': None, 'min_samples_split': 3, 'random_state': None}\n"
     ]
    }
   ],
   "source": [
    "DecisionTree_model = DecisionTreeRegressor()\n",
    "DecisionTree_cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define DecisionTree_grid\n",
    "DecisionTree_grid = dict()\n",
    "\n",
    "DecisionTree_grid['max_depth'] = [None, 5]\n",
    "DecisionTree_grid['min_samples_split'] = [1,2,3,4,5]\n",
    "DecisionTree_grid['random_state'] = [None, 1, 2]\n",
    "\n",
    "DecisionTree_search = GridSearchCV(DecisionTree_model, DecisionTree_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "DecisionTree_results = DecisionTree_search.fit(Train_X, Train_Y)\n",
    "print('Negative MAPE:' , DecisionTree_results.best_score_)\n",
    "print('Best params are : %s'% DecisionTree_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90b921ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.09283874293326487\n",
      "Best params are : {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "DecisionTree_model = DecisionTreeRegressor()\n",
    "DecisionTree_cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define DecisionTree_grid\n",
    "DecisionTree_grid = dict()\n",
    "\n",
    "\n",
    "DecisionTree_grid['max_depth'] = [None, 5, 10, 15]\n",
    "DecisionTree_grid['min_samples_split'] = [1,2,3,4,5]\n",
    "DecisionTree_grid['min_samples_leaf'] = [1, 2, 3, 4, 5]\n",
    "\n",
    "DecisionTree_search = GridSearchCV(DecisionTree_model, DecisionTree_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "DecisionTree_results = DecisionTree_search.fit(Train_X, Train_Y)\n",
    "print('Negative MAPE:' , DecisionTree_results.best_score_)\n",
    "print('Best params are : %s'% DecisionTree_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e270c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -0.09289034906808695\n",
      "Best params are : {'ccp_alpha': 0.01, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "DecisionTree_model = DecisionTreeRegressor()\n",
    "DecisionTree_cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define DecisionTree_grid\n",
    "DecisionTree_grid = dict()\n",
    "\n",
    "\n",
    "DecisionTree_grid['min_samples_split'] = [1,2,3,4,5]\n",
    "DecisionTree_grid['min_samples_leaf'] = [1, 2, 3, 4, 5]\n",
    "DecisionTree_grid['ccp_alpha'] = [0, 0.01, 0.1, 1]\n",
    "DecisionTree_grid['max_features'] = ['sqrt', 'log2', None]\n",
    "\n",
    "DecisionTree_search = GridSearchCV(DecisionTree_model, DecisionTree_grid, scoring='neg_mean_absolute_percentage_error', cv=cv, n_jobs=-1)\n",
    "DecisionTree_results = DecisionTree_search.fit(Train_X, Train_Y)\n",
    "print('Negative MAPE:' , DecisionTree_results.best_score_)\n",
    "print('Best params are : %s'% DecisionTree_results.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2909b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda5bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a998b55",
   "metadata": {},
   "source": [
    "# voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307077f",
   "metadata": {},
   "source": [
    "Using decision tree, random forest, and bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a23d8",
   "metadata": {},
   "source": [
    "voting before tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f2656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -  0.0833328056555178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "DecisionTree_model = DecisionTreeRegressor()\n",
    "RandomForest_model = RandomForestRegressor()\n",
    "bagging = BaggingRegressor(n_estimators =150)\n",
    "\n",
    "votingModel = VotingRegressor([('DecisionTree_model', DecisionTree_model), ('RandomForest_model', RandomForest_model), ('bagging', bagging)])\n",
    "votingModel=votingModel.fit(Train_X, rav_train_Y)\n",
    "\n",
    "voting_pred = votingModel.predict(Test_X)\n",
    "\n",
    "print('Negative MAPE: - ', mean_absolute_percentage_error( rav_test_Y,voting_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8b616",
   "metadata": {},
   "source": [
    "tune voting algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e42c46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: (0.4, 0.3, 0.3), NMAPE:- 0.08368354\n",
      "Weights: (0.3, 0.3, 0.4), NMAPE:- 0.08330798\n",
      "Weights: (0.3, 0.4, 0.3), NMAPE:- 0.08363307\n",
      "Weights: (0.3333, 0.3333, 0.3334), NMAPE:- 0.08359534\n",
      "Weights: (0.2, 0.2, 0.6), NMAPE:- 0.08355618\n",
      "Weights: (0.6, 0.2, 0.2), NMAPE:- 0.08430581\n",
      "Weights: (0.2, 0.6, 0.2), NMAPE:- 0.08349566\n",
      "Weights: (0.4, 0.4, 0.2), NMAPE:- 0.08348641\n",
      "Weights: (0.4, 0.2, 0.4), NMAPE:- 0.08372747\n",
      "Weights: (0.2, 0.4, 0.4), NMAPE:- 0.08356614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Create base estimators\n",
    "dt = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "bagging = BaggingRegressor(n_estimators=150)\n",
    "\n",
    "# Create voting regressor ensemble\n",
    "ensemble = VotingRegressor(estimators=[('dt', dt), ('rf', rf), ('bagging', bagging)])\n",
    "\n",
    "# Define weight values to test\n",
    "weight_list = [(0.4, 0.3, 0.3),(0.3, 0.3, 0.4),(0.3, 0.4, 0.3),(0.3333, 0.3333, 0.3334),(0.2, 0.2, 0.6),\n",
    "              (0.6, 0.2, 0.2),(0.2, 0.6, 0.2),(0.4, 0.4, 0.2),(0.4, 0.2, 0.4),(0.2, 0.4, 0.4)]\n",
    "\n",
    "# Train and evaluate ensemble for each weight combination\n",
    "for weights in weight_list:\n",
    "  # Set weights in ensemble\n",
    "  ensemble.weights = weights\n",
    "  \n",
    "  # Train ensemble on training data\n",
    "  ensemble.fit(Train_X, rav_train_Y)\n",
    "  \n",
    "  # Evaluate ensemble on test data\n",
    "  voting_tuning_pred = ensemble.predict(Test_X)\n",
    "  mape = mean_absolute_percentage_error( rav_test_Y,voting_tuning_pred)\n",
    "  # Print weight values and RMSE score\n",
    "  print(f\"Weights: {weights}, NMAPE:- {mape:.8f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac067e",
   "metadata": {},
   "source": [
    "The best negative MAPE is -0.08330798, and the weights are (0.3,0.3,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fbb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3e2b2e9",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1837d",
   "metadata": {},
   "source": [
    "stacking model tune meta regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a09f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END meta_regressor=LinearRegression();, score=-0.091 total time= 8.2min\n",
      "[CV 3/5] END ...........meta_regressor=Ridge();, score=-0.089 total time= 8.2min\n",
      "[CV 5/5] END ...........meta_regressor=Ridge();, score=-0.091 total time= 8.2min\n",
      "[CV 4/5] END meta_regressor=LinearRegression();, score=-0.090 total time= 8.2min\n",
      "[CV 1/5] END ...........meta_regressor=Ridge();, score=-0.090 total time= 8.2min\n",
      "[CV 4/5] END ...........meta_regressor=Ridge();, score=-0.090 total time= 8.2min\n",
      "[CV 1/5] END meta_regressor=LinearRegression();, score=-0.090 total time= 8.2min\n",
      "[CV 3/5] END meta_regressor=LinearRegression();, score=-0.089 total time= 8.2min\n",
      "[CV 2/5] END meta_regressor=LinearRegression();, score=-0.090 total time= 8.2min\n",
      "[CV 2/5] END ...........meta_regressor=Ridge();, score=-0.090 total time= 8.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but BaggingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/nina/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0     476.145979      0.823954        13.526047        0.736364   \n",
      "1     476.200717      0.683234        13.434675        0.610314   \n",
      "\n",
      "  param_meta_regressor                                  params  \\\n",
      "0   LinearRegression()  {'meta_regressor': LinearRegression()}   \n",
      "1              Ridge()             {'meta_regressor': Ridge()}   \n",
      "\n",
      "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0          -0.090359          -0.090075          -0.089300          -0.089959   \n",
      "1          -0.090255          -0.090019          -0.089134          -0.089932   \n",
      "\n",
      "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0          -0.090728        -0.090084        0.000473                2  \n",
      "1          -0.090748        -0.090018        0.000525                1  \n",
      "Negative MAPE:  -0.09001769776008903\n",
      "Best param are :  {'meta_regressor': Ridge()}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb \n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "\n",
    "stacking_grid = dict()\n",
    "# etr = ExtraTreesRegressor(n_estimators = 80)\n",
    "# bagging = BaggingRegressor(n_estimators= 9)\n",
    "# xgb = xgb.XGBRegressor(eta= 0.21000000000000002, max_depth= 15)\n",
    "lr = LinearRegression()\n",
    "Ridge_model = Ridge()\n",
    "\n",
    "DecisionTree_model = DecisionTreeRegressor()\n",
    "DecisionTree_model = RandomForestRegressor()\n",
    "bagging = BaggingRegressor(n_estimators =150)\n",
    "\n",
    "\n",
    "regressors = [DecisionTree_model,bagging,DecisionTree_model]\n",
    "stregr = StackingCVRegressor(regressors=regressors, meta_regressor=lr)\n",
    "\n",
    "\n",
    "\n",
    "Stacking_search = GridSearchCV(estimator=stregr, param_grid={'meta_regressor': [lr,Ridge_model]} ,\n",
    "                    cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1, verbose = 4,\n",
    "                    refit=True)\n",
    "\n",
    "\n",
    "\n",
    "Stacking_results = Stacking_search.fit(Train_X, rav_train_Y)\n",
    "stacking_pred = Stacking_search.predict(Test_X)\n",
    "\n",
    "print(pd.DataFrame(Stacking_search.cv_results_))\n",
    "print('Negative MAPE: ', Stacking_results.best_score_)\n",
    "print('Best param are : ' , Stacking_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3161a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a455a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e6075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfb6b124",
   "metadata": {},
   "source": [
    "# best performance model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b3e0351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative MAPE: -  0.08349298590643765\n",
      "MSE:  1892035.0417698033\n",
      "RMSE  1375.5126468956232\n",
      "MAE  593.9537599454592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "DecisionTree_model = DecisionTreeRegressor()\n",
    "RandomForest_model = RandomForestRegressor()\n",
    "bagging = BaggingRegressor(n_estimators =150)\n",
    "\n",
    "# define weights\n",
    "weights = [0.3, 0.3, 0.4]\n",
    "\n",
    "votingModel = VotingRegressor([('DecisionTree_model', DecisionTree_model), ('RandomForest_model', RandomForest_model), ('bagging', bagging)],\n",
    "                             weights=weights)\n",
    "\n",
    "votingModel=votingModel.fit(Train_X, rav_train_Y)\n",
    "\n",
    "voting_pred_best_para = votingModel.predict(Test_X)\n",
    "\n",
    "mape = mean_absolute_percentage_error(rav_test_Y,voting_pred_best_para)\n",
    "mse = mean_squared_error(rav_test_Y,voting_pred_best_para)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(rav_test_Y,voting_pred_best_para)\n",
    "\n",
    "\n",
    "print('Negative MAPE: - ', mape)\n",
    "print('MSE: ', mse)\n",
    "print('RMSE ' , rmse)\n",
    "print('MAE ' , mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d654085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e52b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
